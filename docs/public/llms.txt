# Mastra

> Mastra is an open-source TypeScript agent framework designed to provide the essential primitives for building AI applications. It enables developers to create AI agents with memory and tool-calling capabilities, implement deterministic LLM workflows, and leverage RAG for knowledge integration. With features like model routing, workflow graphs, and automated evals, Mastra provides a complete toolkit for developing, testing, and deploying AI applications.

This documentation covers everything from getting started to advanced features, APIs, and best practices for working with Mastra's agent-based architecture.

The documentation is organized into key sections:
- **docs**: Core documentation covering concepts, features, and implementation details
- **examples**: Practical examples and use cases demonstrating Mastra's capabilities
- **showcase**: A showcase of applications built using Mastra

Each section contains detailed markdown files that provide comprehensive information about Mastra's features and how to use them effectively.


## en
- [Agent Tool Selection | Agent Documentation | Mastra](https://mastra.ai/en/docs/agents/adding-tools): Tools are typed functions that can be executed by agents or workflows, with built-in integration access and parameter validation. Each tool has a schema that defines its inputs, an executor function that implements its logic, and access to configured integrations.
- [adding-voice](https://mastra.ai/en/docs/agents/adding-voice)
- [Using Agent Memory | Agents | Mastra Docs](https://mastra.ai/en/docs/agents/agent-memory): Documentation on how agents in Mastra use memory to store conversation history and contextual information.
- [Using MCP With Mastra | Agents | Mastra Docs](https://mastra.ai/en/docs/agents/mcp-guide): Use MCP in Mastra to integrate third party tools and resources in your AI agents.
- [Creating and Calling Agents | Agent Documentation | Mastra](https://mastra.ai/en/docs/agents/overview): Overview of agents in Mastra, detailing their capabilities and how they interact with tools, workflows, and external systems.
- [Discord Community and Bot | Documentation | Mastra](https://mastra.ai/en/docs/community/discord): Information about the Mastra Discord community and MCP bot.
- [Licensing](https://mastra.ai/en/docs/community/licensing): Mastra License
- [MastraClient](https://mastra.ai/en/docs/deployment/client): Learn how to set up and use the Mastra Client SDK
- [Serverless Deployment](https://mastra.ai/en/docs/deployment/deployment): Build and deploy Mastra applications using platform-specific deployers or standard HTTP servers
- [Creating A Mastra Server](https://mastra.ai/en/docs/deployment/server): Configure and customize the Mastra server with middleware and other options
- [Create your own Eval](https://mastra.ai/en/docs/evals/custom-eval): Mastra allows so create your own evals, here is how.
- [Overview](https://mastra.ai/en/docs/evals/overview): Understanding how to evaluate and measure AI agent quality using Mastra evals.
- [Running in CI](https://mastra.ai/en/docs/evals/running-in-ci): Learn how to run Mastra evals in your CI/CD pipeline to monitor agent quality over time.
- [Textual Evals](https://mastra.ai/en/docs/evals/textual-evals): Understand how Mastra uses LLM-as-judge methodology to evaluate text quality.
- [Licensing](https://mastra.ai/en/docs/faq): Mastra License
- [Using with Vercel AI SDK](https://mastra.ai/en/docs/frameworks/ai-sdk): Learn how Mastra leverages the Vercel AI SDK library and how you can leverage it further with Mastra
- [Getting started with Mastra and NextJS | Mastra Guides](https://mastra.ai/en/docs/frameworks/next-js): Guide on integrating Mastra with NextJS.
- [Installing Mastra Locally | Getting Started | Mastra Docs](https://mastra.ai/en/docs/getting-started/installation): Guide on installing Mastra and setting up the necessary prerequisites for running it with various LLM providers.
- [Using with Cursor/Windsurf | Getting Started | Mastra Docs](https://mastra.ai/en/docs/getting-started/mcp-docs-server): Learn how to use the Mastra MCP documentation server in your IDE to turn it into an agentic Mastra expert.
- [model-capability](https://mastra.ai/en/docs/getting-started/model-capability)
- [Local Project Structure | Getting Started | Mastra Docs](https://mastra.ai/en/docs/getting-started/project-structure): Guide on organizing folders and files in Mastra, including best practices and recommended structures.
- [Introduction | Mastra Docs](https://mastra.ai/en/docs): Mastra is a TypeScript agent framework. It helps you build AI applications and features quickly. It gives you the set of primitives you need: workflows, agents, RAG, integrations, syncs and evals.
- [Using Mastra Integrations | Mastra Local Development Docs](https://mastra.ai/en/docs/integrations): Documentation for Mastra integrations, which are auto-generated, type-safe API clients for third-party services.
- [Adding to an Existing Project | Mastra Local Development Docs](https://mastra.ai/en/docs/local-dev/add-to-existing-project): Add Mastra to your existing Node.js applications
- [Creating a new Project | Mastra Local Development Docs](https://mastra.ai/en/docs/local-dev/creating-a-new-project): Create new Mastra projects or add Mastra to existing Node.js applications using the CLI
- [Inspecting Agents with `mastra dev` | Mastra Local Dev Docs](https://mastra.ai/en/docs/local-dev/mastra-dev): Documentation for the Mastra local development environment for Mastra applications.
- [memory-processors](https://mastra.ai/en/docs/memory/memory-processors)
- [overview](https://mastra.ai/en/docs/memory/overview)
- [semantic-recall](https://mastra.ai/en/docs/memory/semantic-recall)
- [working-memory](https://mastra.ai/en/docs/memory/working-memory)
- [Logging | Mastra Observability Documentation](https://mastra.ai/en/docs/observability/logging): Documentation on effective logging in Mastra, crucial for understanding application behavior and improving AI accuracy.
- [Next.js Tracing | Mastra Observability Documentation](https://mastra.ai/en/docs/observability/nextjs-tracing): Set up OpenTelemetry tracing for Next.js applications
- [Tracing | Mastra Observability Documentation](https://mastra.ai/en/docs/observability/tracing): Set up OpenTelemetry tracing for Mastra applications
- [Chunking and Embedding Documents | RAG | Mastra Docs](https://mastra.ai/en/docs/rag/chunking-and-embedding): Guide on chunking and embedding documents in Mastra for efficient processing and retrieval.
- [RAG (Retrieval-Augmented Generation) in Mastra | Mastra Docs](https://mastra.ai/en/docs/rag/overview): Overview of Retrieval-Augmented Generation (RAG) in Mastra, detailing its capabilities for enhancing LLM outputs with relevant context.
- [Retrieval, Semantic Search, Reranking | RAG | Mastra Docs](https://mastra.ai/en/docs/rag/retrieval): Guide on retrieval processes in Mastras RAG systems, including semantic search, filtering, and re-ranking.
- [Storing Embeddings in A Vector Database | Mastra Docs](https://mastra.ai/en/docs/rag/vector-databases): Guide on vector storage options in Mastra, including embedded and dedicated vector databases for similarity search.
- [Storage in Mastra | Mastra Docs](https://mastra.ai/en/docs/storage/overview): Overview of Mastras storage system and data persistence capabilities.
- [Voice in Mastra | Mastra Docs](https://mastra.ai/en/docs/voice/overview): Overview of voice capabilities in Mastra, including text-to-speech, speech-to-text, and real-time speech-to-speech interactions.
- [Speech-to-Speech Capabilities in Mastra | Mastra Docs](https://mastra.ai/en/docs/voice/speech-to-speech): Overview of speech-to-speech capabilities in Mastra, including real-time interactions and event-driven architecture.
- [Speech-to-Text (STT) in Mastra | Mastra Docs](https://mastra.ai/en/docs/voice/speech-to-text): Overview of Speech-to-Text capabilities in Mastra, including configuration, usage, and integration with voice providers.
- [Text-to-Speech (TTS) in Mastra | Mastra Docs](https://mastra.ai/en/docs/voice/text-to-speech): Overview of Text-to-Speech capabilities in Mastra, including configuration, usage, and integration with voice providers.
- [Branching, Merging, Conditions | Workflows | Mastra Docs](https://mastra.ai/en/docs/workflows/control-flow): Control flow in Mastra workflows allows you to manage branching, merging, and conditions to construct workflows that meet your logic requirements.
- [Dynamic Workflows | Mastra Docs](https://mastra.ai/en/docs/workflows/dynamic-workflows): Learn how to create dynamic workflows within workflow steps, allowing for flexible workflow creation based on runtime conditions.
- [Error Handling in Workflows | Mastra Docs](https://mastra.ai/en/docs/workflows/error-handling): Learn how to handle errors in Mastra workflows using step retries, conditional branching, and monitoring.
- [nested-workflows](https://mastra.ai/en/docs/workflows/nested-workflows)
- [Handling Complex LLM Operations | Workflows | Mastra](https://mastra.ai/en/docs/workflows/overview): Workflows in Mastra help you orchestrate complex sequences of operations with features like branching, parallel execution, resource suspension, and more.
- [Creating Steps and Adding to Workflows | Mastra Docs](https://mastra.ai/en/docs/workflows/steps): Steps in Mastra workflows provide a structured way to manage operations by defining inputs, outputs, and execution logic.
- [Suspend & Resume Workflows | Human-in-the-Loop | Mastra Docs](https://mastra.ai/en/docs/workflows/suspend-and-resume): Suspend and resume in Mastra workflows allows you to pause execution while waiting for external input or resources.
- [Data Mapping with Workflow Variables | Mastra Docs](https://mastra.ai/en/docs/workflows/variables): Learn how to use workflow variables to map data between steps and create dynamic data flows in your Mastra workflows.
- [Example: Adding Voice Capabilities | Agents | Mastra](https://mastra.ai/en/examples/agents/adding-voice-capabilities): Example of adding voice capabilities to Mastra agents, enabling them to speak and listen using different voice providers.
- [Example: Calling Agentic Workflows | Agents | Mastra Docs](https://mastra.ai/en/examples/agents/agentic-workflows): Example of creating AI workflows in Mastra, demonstrating integration of external APIs with LLM-powered planning.
- [Example: Categorizing Birds | Agents | Mastra Docs](https://mastra.ai/en/examples/agents/bird-checker): Example of using a Mastra AI Agent to determine if an image from Unsplash depicts a bird.
- [Example: Hierarchical Multi-Agent System | Agents | Mastra](https://mastra.ai/en/examples/agents/hierarchical-multi-agent): Example of creating a hierarchical multi-agent system using Mastra, where agents interact through tool functions.
- [Example: Multi-Agent Workflow | Agents | Mastra Docs](https://mastra.ai/en/examples/agents/multi-agent-workflow): Example of creating an agentic workflow in Mastra, where work product is passed between multiple agents.
- [Example: Agents with a System Prompt | Agents | Mastra Docs](https://mastra.ai/en/examples/agents/system-prompt): Example of creating an AI agent in Mastra with a system prompt to define its personality and capabilities.
- [Example: Giving an Agent a Tool | Agents | Mastra Docs](https://mastra.ai/en/examples/agents/using-a-tool): Example of creating an AI agent in Mastra that uses a dedicated tool to provide weather information.
- [Example: Answer Relevancy | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/answer-relevancy): Example of using the Answer Relevancy metric to evaluate response relevancy to queries.
- [Example: Bias | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/bias): Example of using the Bias metric to evaluate responses for various forms of bias.
- [Example: Completeness | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/completeness): Example of using the Completeness metric to evaluate how thoroughly responses cover input elements.
- [Example: Content Similarity | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/content-similarity): Example of using the Content Similarity metric to evaluate text similarity between content.
- [Example: Context Position | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/context-position): Example of using the Context Position metric to evaluate sequential ordering in responses.
- [Example: Context Precision | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/context-precision): Example of using the Context Precision metric to evaluate how precisely context information is used.
- [Example: Context Relevancy | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/context-relevancy): Example of using the Context Relevancy metric to evaluate how relevant context information is to a query.
- [Example: Contextual Recall | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/contextual-recall): Example of using the Contextual Recall metric to evaluate how well responses incorporate context information.
- [Example: Custom Eval | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/custom-eval): Example of creating custom LLM-based evaluation metrics in Mastra.
- [Example: Faithfulness | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/faithfulness): Example of using the Faithfulness metric to evaluate how factually accurate responses are compared to context.
- [Example: Hallucination | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/hallucination): Example of using the Hallucination metric to evaluate factual contradictions in responses.
- [Example: Keyword Coverage | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/keyword-coverage): Example of using the Keyword Coverage metric to evaluate how well responses cover important keywords from input text.
- [Example: Prompt Alignment | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/prompt-alignment): Example of using the Prompt Alignment metric to evaluate instruction adherence in responses.
- [Example: Summarization | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/summarization): Example of using the Summarization metric to evaluate how well LLM-generated summaries capture content while maintaining factual accuracy.
- [Example: Textual Difference | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/textual-difference): Example of using the Textual Difference metric to evaluate similarity between text strings by analyzing sequence differences and changes.
- [Example: Tone Consistency | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/tone-consistency): Example of using the Tone Consistency metric to evaluate emotional tone patterns and sentiment consistency in text.
- [Example: Toxicity | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/toxicity): Example of using the Toxicity metric to evaluate responses for harmful content and toxic language.
- [Example: Word Inclusion | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/word-inclusion): Example of creating a custom metric to evaluate word inclusion in output text.
- [Examples List: Workflows, Agents, RAG | Mastra Docs](https://mastra.ai/en/examples): Explore practical examples of AI development with Mastra, including text generation, RAG implementations, structured outputs, and multi-modal interactions. Learn how to build AI applications using OpenAI, Anthropic, and Google Gemini.
- [Memory Processors](https://mastra.ai/en/examples/memory/memory-processors): Example of using memory processors to filter and transform recalled messages
- [memory-with-libsql](https://mastra.ai/en/examples/memory/memory-with-libsql)
- [memory-with-pg](https://mastra.ai/en/examples/memory/memory-with-pg)
- [memory-with-upstash](https://mastra.ai/en/examples/memory/memory-with-upstash)
- [Streaming Working Memory (advanced)](https://mastra.ai/en/examples/memory/streaming-working-memory-advanced): Example of using working memory to maintain a todo list across conversations
- [Streaming Working Memory](https://mastra.ai/en/examples/memory/streaming-working-memory): Example of using working memory with an agent
- [AI SDK useChat Hook](https://mastra.ai/en/examples/memory/use-chat): Example showing how to integrate Mastra memory with the Vercel AI SDK useChat hook.
- [Example: Adjusting Chunk Delimiters | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/chunking/adjust-chunk-delimiters): Adjust chunk delimiters in Mastra to better match your content structure.
- [Example: Adjusting The Chunk Size | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/chunking/adjust-chunk-size): Adjust chunk size in Mastra to better match your content and memory requirements.
- [Example: Semantically Chunking HTML | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/chunking/chunk-html): Chunk HTML content in Mastra to semantically chunk the document.
- [Example: Semantically Chunking JSON | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/chunking/chunk-json): Chunk JSON data in Mastra to semantically chunk the document.
- [Example: Semantically Chunking Markdown | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/chunking/chunk-markdown): Example of using Mastra to chunk markdown documents for search or retrieval purposes.
- [Example: Semantically Chunking Text | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/chunking/chunk-text): Example of using Mastra to split large text documents into smaller chunks for processing.
- [Example: Embedding Chunk Arrays | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/embedding/embed-chunk-array): Example of using Mastra to generate embeddings for an array of text chunks for similarity search.
- [Example: Embedding Text Chunks | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/embedding/embed-text-chunk): Example of using Mastra to generate an embedding for a single text chunk for similarity search.
- [Example: Embedding Text with Cohere | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/embedding/embed-text-with-cohere): Example of using Mastra to generate embeddings using Coheres embedding model.
- [Example: Metadata Extraction | Retrieval | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/embedding/metadata-extraction): Example of extracting and utilizing metadata from documents in Mastra for enhanced document processing and retrieval.
- [Example: Hybrid Vector Search | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/query/hybrid-vector-search): Example of using metadata filters with PGVector to enhance vector search results in Mastra.
- [Example: Retrieving Top-K Results | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/query/retrieve-results): Example of using Mastra to query a vector database and retrieve semantically similar chunks.
- [Example: Re-ranking Results with Tools | Retrieval | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/rerank/rerank-rag): Example of implementing a RAG system with re-ranking in Mastra using OpenAI embeddings and PGVector for vector storage.
- [Example: Re-ranking Results | Retrieval | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/rerank/rerank): Example of implementing semantic re-ranking in Mastra using OpenAI embeddings and PGVector for vector storage.
- [Example: Reranking with Cohere | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/rerank/reranking-with-cohere): Example of using Mastra to improve document retrieval relevance with Coheres reranking service.
- [Example: Upsert Embeddings | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/upsert/upsert-embeddings): Examples of using Mastra to store embeddings in various vector databases for similarity search.
- [Example: Using the Vector Query Tool | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/usage/basic-rag): Example of implementing a basic RAG system in Mastra using OpenAI embeddings and PGVector for vector storage.
- [Example: Optimizing Information Density | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/usage/cleanup-rag): Example of implementing a RAG system in Mastra to optimize information density and deduplicate data using LLM-based processing.
- [Example: Chain of Thought Prompting | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/usage/cot-rag): Example of implementing a RAG system in Mastra with chain-of-thought reasoning using OpenAI and PGVector.
- [Example: Structured Reasoning with Workflows | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/usage/cot-workflow-rag): Example of implementing structured reasoning in a RAG system using Mastras workflow capabilities.
- [Example: Agent-Driven Metadata Filtering | Retrieval | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/usage/filter-rag): Example of using a Mastra agent in a RAG system to construct and apply metadata filters for document retrieval.
- [Example: A Complete Graph RAG System | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/usage/graph-rag): Example of implementing a Graph RAG system in Mastra using OpenAI embeddings and PGVector for vector storage.
- [Example: Speech to Text | Voice | Mastra Docs](https://mastra.ai/en/examples/voice/speech-to-text): Example of using Mastra to create a speech to text application.
- [Example: Text to Speech | Voice | Mastra Docs](https://mastra.ai/en/examples/voice/text-to-speech): Example of using Mastra to create a text to speech application.
- [Example: Branching Paths | Workflows | Mastra Docs](https://mastra.ai/en/examples/workflows/branching-paths): Example of using Mastra to create workflows with branching paths based on intermediate results.
- [Example: Calling an Agent from a Workflow | Mastra Docs](https://mastra.ai/en/examples/workflows/calling-agent): Example of using Mastra to call an AI agent from within a workflow step.
- [Example: Conditional Branching (experimental) | Workflows | Mastra Docs](https://mastra.ai/en/examples/workflows/conditional-branching): Example of using Mastra to create conditional branches in workflows using if/else statements.
- [Example: Creating a Workflow | Workflows | Mastra Docs](https://mastra.ai/en/examples/workflows/creating-a-workflow): Example of using Mastra to define and execute a simple workflow with a single step.
- [Example: Cyclical Dependencies | Workflows | Mastra Docs](https://mastra.ai/en/examples/workflows/cyclical-dependencies): Example of using Mastra to create workflows with cyclical dependencies and conditional loops.
- [Example: Human in the Loop | Workflows | Mastra Docs](https://mastra.ai/en/examples/workflows/human-in-the-loop): Example of using Mastra to create workflows with human intervention points.
- [Example: Parallel Execution | Workflows | Mastra Docs](https://mastra.ai/en/examples/workflows/parallel-steps): Example of using Mastra to execute multiple independent tasks in parallel within a workflow.
- [Example: Sequential Steps | Workflows | Mastra Docs](https://mastra.ai/en/examples/workflows/sequential-steps): Example of using Mastra to chain workflow steps in a specific sequence, passing data between them.
- [Example: Suspend and Resume | Workflows | Mastra Docs](https://mastra.ai/en/examples/workflows/suspend-and-resume): Example of using Mastra to suspend and resume workflow steps during execution.
- [Example: Using a Tool as a Step | Workflows | Mastra Docs](https://mastra.ai/en/examples/workflows/using-a-tool-as-a-step): Example of using Mastra to integrate a custom tool as a step in a workflow.
- [Data Mapping with Workflow Variables | Mastra Examples](https://mastra.ai/en/examples/workflows/workflow-variables): Learn how to use workflow variables to map data between steps in Mastra workflows.
- [Building an AI Recruiter | Mastra Workflows | Guides](https://mastra.ai/en/guides/guide/ai-recruiter): Guide on building a recruiter workflow in Mastra to gather and process candidate information using LLMs.
- [Building an AI Chef Assistant | Mastra Agent Guides](https://mastra.ai/en/guides/guide/chef-michel): Guide on creating a Chef Assistant agent in Mastra to help users cook meals with available ingredients.
- [Building a Research Paper Assistant | Mastra RAG Guides](https://mastra.ai/en/guides/guide/research-assistant): Guide on creating an AI research assistant that can analyze and answer questions about academic papers using RAG.
- [Building an AI Stock Agent | Mastra Agents | Guides](https://mastra.ai/en/guides/guide/stock-agent): Guide on creating a simple stock agent in Mastra to fetch the last days closing stock price for a given symbol.
- [Overview](https://mastra.ai/en/guides): Guides on building with Mastra
- [Reference: createTool() | Tools | Agents | Mastra Docs](https://mastra.ai/en/reference/agents/createTool): Documentation for the createTool function in Mastra, which creates custom tools for agents and workflows.
- [Reference: Agent.generate() | Agents | Mastra Docs](https://mastra.ai/en/reference/agents/generate): Documentation for the `.generate()` method in Mastra agents, which produces text or structured responses.
- [Reference: getAgent() | Agent Config | Agents | Mastra Docs](https://mastra.ai/en/reference/agents/getAgent): API Reference for getAgent.
- [Reference: Agent.stream() | Streaming | Agents | Mastra Docs](https://mastra.ai/en/reference/agents/stream): Documentation for the `.stream()` method in Mastra agents, which enables real-time streaming of responses.
- [mastra build](https://mastra.ai/en/reference/cli/build): Build your Mastra project for production deployment
- [`mastra dev` Reference | Local Development | Mastra CLI](https://mastra.ai/en/reference/cli/dev): Documentation for the mastra dev command, which starts a development server for agents, tools, and workflows.
- [`mastra init` reference | Project Creation | Mastra CLI](https://mastra.ai/en/reference/cli/init): Documentation for the mastra init command, which creates a new Mastra project with interactive setup options.
- [agents](https://mastra.ai/en/reference/client-js/agents)
- [error-handling](https://mastra.ai/en/reference/client-js/error-handling)
- [logs](https://mastra.ai/en/reference/client-js/logs)
- [memory](https://mastra.ai/en/reference/client-js/memory)
- [telemetry](https://mastra.ai/en/reference/client-js/telemetry)
- [tools](https://mastra.ai/en/reference/client-js/tools)
- [vectors](https://mastra.ai/en/reference/client-js/vectors)
- [workflows](https://mastra.ai/en/reference/client-js/workflows)
- [Mastra Core](https://mastra.ai/en/reference/core/mastra-class): Documentation for the Mastra Class, the core entry point for managing agents, workflows, and server endpoints.
- [Cloudflare Deployer](https://mastra.ai/en/reference/deployer/cloudflare): Documentation for the CloudflareDeployer class, which deploys Mastra applications to Cloudflare Workers.
- [Mastra Deployer](https://mastra.ai/en/reference/deployer/deployer): Documentation for the Deployer abstract class, which handles packaging and deployment of Mastra applications.
- [Netlify Deployer](https://mastra.ai/en/reference/deployer/netlify): Documentation for the NetlifyDeployer class, which deploys Mastra applications to Netlify Functions.
- [Vercel Deployer](https://mastra.ai/en/reference/deployer/vercel): Documentation for the VercelDeployer class, which deploys Mastra applications to Vercel.
- [Reference: Answer Relevancy | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/answer-relevancy): Documentation for the Answer Relevancy Metric in Mastra, which evaluates how well LLM outputs address the input query.
- [Reference: Bias | Output Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/bias): Documentation for the Bias Metric in Mastra, which evaluates LLM outputs for various forms of bias, including gender, political, racial/ethnic, or geographical bias.
- [Reference: Completeness | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/completeness): Documentation for the Completeness Metric in Mastra, which evaluates how thoroughly LLM outputs cover key elements present in the input.
- [Reference: Content Similarity | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/content-similarity): Documentation for the Content Similarity Metric in Mastra, which measures textual similarity between strings and provides a matching score.
- [Reference: Context Position | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/context-position): Documentation for the Context Position Metric in Mastra, which evaluates the ordering of context nodes based on their relevance to the query and output.
- [Reference: Context Precision | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/context-precision): Documentation for the Context Precision Metric in Mastra, which evaluates the relevance and precision of retrieved context nodes for generating expected outputs.
- [Reference: Context Relevancy | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/context-relevancy): Documentation for the Context Relevancy Metric, which evaluates the relevance of retrieved context in RAG pipelines.
- [Reference: Contextual Recall | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/contextual-recall): Documentation for the Contextual Recall Metric, which evaluates the completeness of LLM responses in incorporating relevant context.
- [Reference: Faithfulness | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/faithfulness): Documentation for the Faithfulness Metric in Mastra, which evaluates the factual accuracy of LLM outputs compared to the provided context.
- [Reference: Hallucination | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/hallucination): Documentation for the Hallucination Metric in Mastra, which evaluates the factual correctness of LLM outputs by identifying contradictions with provided context.
- [Reference: Keyword Coverage | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/keyword-coverage): Documentation for the Keyword Coverage Metric in Mastra, which evaluates how well LLM outputs cover important keywords from the input.
- [Reference: Prompt Alignment | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/prompt-alignment): Documentation for the Prompt Alignment Metric in Mastra, which evaluates how well LLM outputs adhere to given prompt instructions.
- [Reference: Summarization | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/summarization): Documentation for the Summarization Metric in Mastra, which evaluates the quality of LLM-generated summaries for content and factual accuracy.
- [Reference: Textual Difference | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/textual-difference): Documentation for the Textual Difference Metric in Mastra, which measures textual differences between strings using sequence matching.
- [Reference: Tone Consistency | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/tone-consistency): Documentation for the Tone Consistency Metric in Mastra, which evaluates emotional tone and sentiment consistency in text.
- [Reference: Toxicity | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/toxicity): Documentation for the Toxicity Metric in Mastra, which evaluates LLM outputs for racist, biased, or toxic elements.
- [API Reference](https://mastra.ai/en/reference): Mastra API Reference
- [Memory](https://mastra.ai/en/reference/memory/Memory)
- [createThread](https://mastra.ai/en/reference/memory/createThread)
- [getThreadById](https://mastra.ai/en/reference/memory/getThreadById)
- [getThreadsByResourceId](https://mastra.ai/en/reference/memory/getThreadsByResourceId)
- [query](https://mastra.ai/en/reference/memory/query)
- [AgentNetwork (Experimental)](https://mastra.ai/en/reference/networks/agent-network): Reference documentation for the AgentNetwork class
- [Reference: createLogger() | Mastra Observability Docs](https://mastra.ai/en/reference/observability/create-logger): Documentation for the createLogger function, which instantiates a logger based on a given configuration.
- [Reference: Logger Instance | Mastra Observability Docs](https://mastra.ai/en/reference/observability/logger): Documentation for Logger instances, which provide methods to record events at various severity levels.
- [Reference: OtelConfig | Mastra Observability Docs](https://mastra.ai/en/reference/observability/otel-config): Documentation for the OtelConfig object, which configures OpenTelemetry instrumentation, tracing, and exporting behavior.
- [Reference: Braintrust | Observability | Mastra Docs](https://mastra.ai/en/reference/observability/providers/braintrust): Documentation for integrating Braintrust with Mastra, an evaluation and monitoring platform for LLM applications.
- [Reference: Dash0 Integration | Mastra Observability Docs](https://mastra.ai/en/reference/observability/providers/dash0): Documentation for integrating Mastra with Dash0, an Open Telementry native observability solution.
- [Reference: Provider List | Observability | Mastra Docs](https://mastra.ai/en/reference/observability/providers): Overview of observability providers supported by Mastra, including Dash0, SigNoz, Braintrust, Langfuse, and more.
- [Reference: Laminar Integration | Mastra Observability Docs](https://mastra.ai/en/reference/observability/providers/laminar): Documentation for integrating Laminar with Mastra, a specialized observability platform for LLM applications.
- [Reference: Langfuse Integration | Mastra Observability Docs](https://mastra.ai/en/reference/observability/providers/langfuse): Documentation for integrating Langfuse with Mastra, an open-source observability platform for LLM applications.
- [Reference: LangSmith Integration | Mastra Observability Docs](https://mastra.ai/en/reference/observability/providers/langsmith): Documentation for integrating LangSmith with Mastra, a platform for debugging, testing, evaluating, and monitoring LLM applications.
- [Reference: LangWatch Integration | Mastra Observability Docs](https://mastra.ai/en/reference/observability/providers/langwatch): Documentation for integrating LangWatch with Mastra, a specialized observability platform for LLM applications.
- [Reference: New Relic Integration | Mastra Observability Docs](https://mastra.ai/en/reference/observability/providers/new-relic): Documentation for integrating New Relic with Mastra, a comprehensive observability platform supporting OpenTelemetry for full-stack monitoring.
- [Reference: SigNoz Integration | Mastra Observability Docs](https://mastra.ai/en/reference/observability/providers/signoz): Documentation for integrating SigNoz with Mastra, an open-source APM and observability platform providing full-stack monitoring through OpenTelemetry.
- [Reference: Traceloop Integration | Mastra Observability Docs](https://mastra.ai/en/reference/observability/providers/traceloop): Documentation for integrating Traceloop with Mastra, an OpenTelemetry-native observability platform for LLM applications.
- [Reference: Astra Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/astra): Documentation for the AstraVector class in Mastra, which provides vector search using DataStax Astra DB.
- [Reference: Chroma Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/chroma): Documentation for the ChromaVector class in Mastra, which provides vector search using ChromaDB.
- [Reference: .chunk() | Document Processing | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/chunk): Documentation for the chunk function in Mastra, which splits documents into smaller segments using various strategies.
- [Reference: MDocument | Document Processing | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/document): Documentation for the MDocument class in Mastra, which handles document processing and chunking.
- [Reference: embed() | Document Embedding | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/embeddings): Documentation for embedding functionality in Mastra using the AI SDK.
- [Reference: ExtractParams | Document Processing | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/extract-params): Documentation for metadata extraction configuration in Mastra.
- [Reference: GraphRAG | Graph-based RAG | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/graph-rag): Documentation for the GraphRAG class in Mastra, which implements a graph-based approach to retrieval augmented generation.
- [Default Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/libsql): Documentation for the LibSQLVector class in Mastra, which provides vector search using LibSQL with vector extensions.
- [Reference: Metadata Filters | Metadata Filtering | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/metadata-filters): Documentation for metadata filtering capabilities in Mastra, which allow for precise querying of vector search results across different vector stores.
- [Reference: PG Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/pg): Documentation for the PgVector class in Mastra, which provides vector search using PostgreSQL with pgvector extension.
- [Reference: Pinecone Vector Store | Vector DBs | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/pinecone): Documentation for the PineconeVector class in Mastra, which provides an interface to Pinecones vector database.
- [Reference: Qdrant Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/qdrant): Documentation for integrating Qdrant with Mastra, a vector similarity search engine for managing vectors and payloads.
- [Reference: Rerank | Document Retrieval | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/rerank): Documentation for the rerank function in Mastra, which provides advanced reranking capabilities for vector search results.
- [Reference: Turbopuffer Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/turbopuffer): Documentation for integrating Turbopuffer with Mastra, a high-performance vector database for efficient similarity search.
- [Reference: Upstash Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/upstash): Documentation for the UpstashVector class in Mastra, which provides vector search using Upstash Vector.
- [Reference: Cloudflare Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/vectorize): Documentation for the CloudflareVector class in Mastra, which provides vector search using Cloudflare Vectorize.
- [LibSQL Storage | Storage System | Mastra Core](https://mastra.ai/en/reference/storage/libsql): Documentation for the LibSQL storage implementation in Mastra.
- [PostgreSQL Storage | Storage System | Mastra Core](https://mastra.ai/en/reference/storage/postgresql): Documentation for the PostgreSQL storage implementation in Mastra.
- [Upstash Storage | Storage System | Mastra Core](https://mastra.ai/en/reference/storage/upstash): Documentation for the Upstash storage implementation in Mastra.
- [Reference: MastraMCPClient | Tool Discovery | Mastra Docs](https://mastra.ai/en/reference/tools/client): API Reference for MastraMCPClient - A client implementation for the Model Context Protocol.
- [Reference: createDocumentChunkerTool() | Tools | Mastra Docs](https://mastra.ai/en/reference/tools/document-chunker-tool): Documentation for the Document Chunker Tool in Mastra, which splits documents into smaller chunks for efficient processing and retrieval.
- [Reference: createGraphRAGTool() | RAG | Mastra Tools Docs](https://mastra.ai/en/reference/tools/graph-rag-tool): Documentation for the Graph RAG Tool in Mastra, which enhances RAG by building a graph of semantic relationships between documents.
- [Reference: MCPConfiguration | Tool Management | Mastra Docs](https://mastra.ai/en/reference/tools/mcp-configuration): API Reference for MCPConfiguration - A class for managing multiple Model Context Protocol servers and their tools.
- [Reference: createVectorQueryTool() | RAG | Mastra Tools Docs](https://mastra.ai/en/reference/tools/vector-query-tool): Documentation for the Vector Query Tool in Mastra, which facilitates semantic search over vector stores with filtering and reranking capabilities.
- [Reference: Azure Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/azure): Documentation for the AzureVoice class, providing text-to-speech and speech-to-text capabilities using Azure Cognitive Services.
- [Reference: Cloudflare Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/cloudflare): Documentation for the CloudflareVoice class, providing text-to-speech capabilities using Cloudflare Workers AI.
- [Reference: CompositeVoice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/composite-voice): Documentation for the CompositeVoice class, which enables combining multiple voice providers for flexible text-to-speech and speech-to-text operations.
- [Reference: Deepgram Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/deepgram): Documentation for the Deepgram voice implementation, providing text-to-speech and speech-to-text capabilities with multiple voice models and languages.
- [Reference: ElevenLabs Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/elevenlabs): Documentation for the ElevenLabs voice implementation, offering high-quality text-to-speech capabilities with multiple voice models and natural-sounding synthesis.
- [Reference: Google Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/google): Documentation for the Google Voice implementation, providing text-to-speech and speech-to-text capabilities.
- [Reference: MastraVoice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/mastra-voice): Documentation for the MastraVoice abstract base class, which defines the core interface for all voice services in Mastra, including speech-to-speech capabilities.
- [Reference: Murf Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/murf): Documentation for the Murf voice implementation, providing text-to-speech capabilities.
- [Reference: OpenAI Realtime Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/openai-realtime): Documentation for the OpenAIRealtimeVoice class, providing real-time text-to-speech and speech-to-text capabilities via WebSockets.
- [Reference: OpenAI Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/openai): Documentation for the OpenAIVoice class, providing text-to-speech and speech-to-text capabilities.
- [Reference: PlayAI Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/playai): Documentation for the PlayAI voice implementation, providing text-to-speech capabilities.
- [Reference: Sarvam Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/sarvam): Documentation for the Sarvam class, providing text-to-speech and speech-to-text capabilities.
- [Reference: Speechify Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/speechify): Documentation for the Speechify voice implementation, providing text-to-speech capabilities.
- [Reference: voice.addInstructions() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.addInstructions): Documentation for the addInstructions() method available in voice providers, which adds instructions to guide the voice models behavior.
- [Reference: voice.addTools() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.addTools): Documentation for the addTools() method available in voice providers, which equips voice models with function calling capabilities.
- [Reference: voice.answer() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.answer): Documentation for the answer() method available in real-time voice providers, which triggers the voice provider to generate a response.
- [Reference: voice.close() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.close): Documentation for the close() method available in voice providers, which disconnects from real-time voice services.
- [Reference: voice.connect() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.connect): Documentation for the connect() method available in real-time voice providers, which establishes a connection for speech-to-speech communication.
- [Reference: Voice Events | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.events): Documentation for events emitted by voice providers, particularly for real-time voice interactions.
- [Reference: voice.getSpeakers() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.getSpeakers): Documentation for the getSpeakers() method available in voice providers, which retrieves available voice options.
- [Reference: voice.listen() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.listen): Documentation for the listen() method available in all Mastra voice providers, which converts speech to text.
- [Reference: voice.off() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.off): Documentation for the off() method available in voice providers, which removes event listeners for voice events.
- [Reference: voice.on() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.on): Documentation for the on() method available in voice providers, which registers event listeners for voice events.
- [Reference: voice.send() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.send): Documentation for the send() method available in real-time voice providers, which streams audio data for continuous processing.
- [Reference: voice.speak() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.speak): Documentation for the speak() method available in all Mastra voice providers, which converts text to speech.
- [Reference: voice.updateConfig() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.updateConfig): Documentation for the updateConfig() method available in voice providers, which updates the configuration of a voice provider at runtime.
- [Reference: .after() | Building Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/after): Documentation for the `after()` method in workflows, enabling branching and merging paths.
- [.afterEvent() Method | Mastra Docs](https://mastra.ai/en/reference/workflows/afterEvent): Reference for the afterEvent method in Mastra workflows that creates event-based suspension points.
- [Reference: Workflow.commit() | Running Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/commit): Documentation for the `.commit()` method in workflows, which re-initializes the workflow machine with the current step configuration.
- [Reference: Workflow.createRun() | Running Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/createRun): Documentation for the `.createRun()` method in workflows, which initializes a new workflow run instance.
- [Reference: Workflow.else() | Conditional Branching | Mastra Docs](https://mastra.ai/en/reference/workflows/else): Documentation for the `.else()` method in Mastra workflows, which creates an alternative branch when an if condition is false.
- [Event-Driven Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/events): Learn how to create event-driven workflows using afterEvent and resumeWithEvent methods in Mastra.
- [Reference: Workflow.execute() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/execute): Documentation for the `.execute()` method in Mastra workflows, which runs workflow steps and returns results.
- [Reference: Workflow.if() | Conditional Branching | Mastra Docs](https://mastra.ai/en/reference/workflows/if): Documentation for the `.if()` method in Mastra workflows, which creates conditional branches based on specified conditions.
- [Reference: run.resume() | Running Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/resume): Documentation for the `.resume()` method in workflows, which continues execution of a suspended workflow step.
- [.resumeWithEvent() Method | Mastra Docs](https://mastra.ai/en/reference/workflows/resumeWithEvent): Reference for the resumeWithEvent method that resumes suspended workflows using event data.
- [Reference: Snapshots | Workflow State Persistence | Mastra Docs](https://mastra.ai/en/reference/workflows/snapshots): Technical reference on snapshots in Mastra - the serialized workflow state that enables suspend and resume functionality
- [Reference: start() | Running Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/start): Documentation for the `start()` method in workflows, which begins execution of a workflow run.
- [Reference: Step | Building Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/step-class): Documentation for the Step class, which defines individual units of work within a workflow.
- [Reference: StepCondition | Building Workflows | Mastra](https://mastra.ai/en/reference/workflows/step-condition): Documentation for the step condition class in workflows, which determines whether a step should execute based on the output of previous steps or trigger data.
- [Reference: Workflow.step() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/step-function): Documentation for the `.step()` method in workflows, which adds a new step to the workflow.
- [Reference: StepOptions | Building Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/step-options): Documentation for the step options in workflows, which control variable mapping, execution conditions, and other runtime behavior.
- [Step Retries | Error Handling | Mastra Docs](https://mastra.ai/en/reference/workflows/step-retries): Automatically retry failed steps in Mastra workflows with configurable retry policies.
- [Reference: suspend() | Control Flow | Mastra Docs](https://mastra.ai/en/reference/workflows/suspend): Documentation for the suspend function in Mastra workflows, which pauses execution until resumed.
- [Reference: Workflow.then() | Building Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/then): Documentation for the `.then()` method in workflows, which creates sequential dependencies between steps.
- [Reference: Workflow.until() | Looping in Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/until): Documentation for the `.until()` method in Mastra workflows, which repeats a step until a specified condition becomes true.
- [Reference: run.watch() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/watch): Documentation for the `.watch()` method in workflows, which monitors the status of a workflow run.
- [Reference: Workflow.while() | Looping in Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/while): Documentation for the `.while()` method in Mastra workflows, which repeats a step as long as a specified condition remains true.
- [Reference: Workflow Class | Building Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/workflow): Documentation for the Workflow class in Mastra, which enables you to create state machines for complex sequences of operations with conditional branching and data validation.
- [Showcase](https://mastra.ai/en/showcase): Check out these applications built with Mastra

## ja
- [エージェントツール選択 | エージェントドキュメント | Mastra](https://mastra.ai/ja/docs/agents/adding-tools): ツールは、エージェントやワークフローによって実行できる型付き関数で、組み込みの統合アクセスとパラメータ検証機能を備えています。各ツールには、入力を定義するスキーマ、ロジックを実装する実行関数、および設定された統合へのアクセスがあります。
- [adding-voice](https://mastra.ai/ja/docs/agents/adding-voice)
- [エージェントメモリーの使用 | エージェント | Mastra ドキュメント](https://mastra.ai/ja/docs/agents/agent-memory): Mastraのエージェントが会話履歴やコンテキスト情報を保存するためにメモリーをどのように使用するかに関するドキュメント。
- [MCPをMastraで使用する | エージェント | Mastraドキュメント](https://mastra.ai/ja/docs/agents/mcp-guide): MastraでMCPを使用して、AIエージェントにサードパーティのツールやリソースを統合します。
- [エージェントの作成と呼び出し | エージェントドキュメンテーション | Mastra](https://mastra.ai/ja/docs/agents/overview): Mastraにおけるエージェントの概要、その機能とツール、ワークフロー、外部システムとの連携方法の詳細。
- [Discord コミュニティとボット | ドキュメント | Mastra](https://mastra.ai/ja/docs/community/discord): Mastra Discordコミュニティとマスターノード認証プログラム（MCP）ボットに関する情報。
- [ライセンス](https://mastra.ai/ja/docs/community/licensing): Mastraライセンス
- [MastraClient](https://mastra.ai/ja/docs/deployment/client): Mastra Client SDKの設定と使用方法について学ぶ
- [サーバーレスデプロイメント](https://mastra.ai/ja/docs/deployment/deployment): プラットフォーム固有のデプロイヤーや標準HTTPサーバーを使用してMastraアプリケーションを構築・デプロイする
- [Mastraサーバーの作成](https://mastra.ai/ja/docs/deployment/server): ミドルウェアやその他のオプションでMastraサーバーを設定およびカスタマイズする
- [独自のEvalを作成する](https://mastra.ai/ja/docs/evals/custom-eval): Mastraを使用すると、独自のevalを作成できます。方法はこちらです。
- [概要](https://mastra.ai/ja/docs/evals/overview): Mastra evalsを使用してAIエージェントの品質を評価および測定する方法を理解する。
- [CIでの実行](https://mastra.ai/ja/docs/evals/running-in-ci): 時間の経過とともにエージェントの品質を監視するために、CI/CDパイプラインでMastraの評価を実行する方法を学びましょう。
- [テキスト評価](https://mastra.ai/ja/docs/evals/textual-evals): MastraがLLM-as-judgeの方法論を使用してテキストの品質を評価する方法を理解する。
- [ライセンス](https://mastra.ai/ja/docs/faq): Mastra ライセンス
- [Vercel AI SDKとの併用](https://mastra.ai/ja/docs/frameworks/ai-sdk): MastraがVercel AI SDKライブラリをどのように活用しているか、そしてMastraでさらにどのように活用できるかを学ぶ
- [Mastraとの連携を始める - NextJS編 | Mastraガイド](https://mastra.ai/ja/docs/frameworks/next-js): MastraとNextJSを連携するためのガイド。
- [Mastraをローカルにインストールする | はじめに | Mastra ドキュメント](https://mastra.ai/ja/docs/getting-started/installation): Mastraのインストールと、さまざまなLLMプロバイダーで実行するために必要な前提条件の設定に関するガイド。
- [Cursor/Windsurfと一緒に使う | はじめに | Mastra ドキュメント](https://mastra.ai/ja/docs/getting-started/mcp-docs-server): Mastra MCP ドキュメントサーバーをIDEで使用して、エージェント的なMastraの専門家に変える方法を学びます。
- [model-capability](https://mastra.ai/ja/docs/getting-started/model-capability)
- [ローカルプロジェクト構造 | はじめに | Mastra ドキュメント](https://mastra.ai/ja/docs/getting-started/project-structure): Mastraでのフォルダとファイルの整理に関するガイド、ベストプラクティスと推奨される構造を含む。
- [はじめに | Mastra ドキュメント](https://mastra.ai/ja/docs): Mastraは、TypeScriptエージェントフレームワークです。AIアプリケーションや機能を素早く構築するのに役立ちます。ワークフロー、エージェント、RAG、統合、同期、評価など、必要なプリミティブセットを提供します。
- [Mastra 統合の使用 | Mastra ローカル開発ドキュメント](https://mastra.ai/ja/docs/integrations): サードパーティサービスのために自動生成された型安全なAPIクライアントであるMastra統合のドキュメント。
- [既存プロジェクトへの追加 | Mastra ローカル開発ドキュメント](https://mastra.ai/ja/docs/local-dev/add-to-existing-project): 既存のNode.jsアプリケーションにMastraを追加する
- [新しいプロジェクトの作成 | Mastra ローカル開発ドキュメント](https://mastra.ai/ja/docs/local-dev/creating-a-new-project): CLIを使用して新しいMastraプロジェクトを作成するか、既存のNode.jsアプリケーションにMastraを追加します
- [`mastra dev`でエージェントを検査する | Mastra ローカル開発ドキュメント](https://mastra.ai/ja/docs/local-dev/mastra-dev): MastraアプリケーションのためのMastraローカル開発環境のドキュメント。
- [memory-processors](https://mastra.ai/ja/docs/memory/memory-processors)
- [overview](https://mastra.ai/ja/docs/memory/overview)
- [semantic-recall](https://mastra.ai/ja/docs/memory/semantic-recall)
- [working-memory](https://mastra.ai/ja/docs/memory/working-memory)
- [ログ | Mastra オブザーバビリティ ドキュメント](https://mastra.ai/ja/docs/observability/logging): Mastra における効果的なログ記録に関するドキュメントで、アプリケーションの動作を理解し、AI の精度を向上させるために重要です。
- [Next.js トレーシング | Mastra オブザーバビリティ ドキュメント](https://mastra.ai/ja/docs/observability/nextjs-tracing): Next.js アプリケーションのための OpenTelemetry トレーシングの設定
- [トレーシング | Mastra オブザーバビリティ ドキュメント](https://mastra.ai/ja/docs/observability/tracing): Mastra アプリケーションのための OpenTelemetry トレーシングの設定
- [ドキュメントのチャンク化と埋め込み | RAG | Mastra ドキュメント](https://mastra.ai/ja/docs/rag/chunking-and-embedding): 効率的な処理と取得のためのMastraにおけるドキュメントのチャンク化と埋め込みに関するガイド。
- [MastraにおけるRAG（検索強化生成） | Mastra ドキュメント](https://mastra.ai/ja/docs/rag/overview): Mastraにおける検索強化生成（RAG）の概要と、関連するコンテキストでLLMの出力を強化するための機能を詳述します。
- [検索、セマンティック検索、再ランキング | RAG | Mastra ドキュメント](https://mastra.ai/ja/docs/rag/retrieval): Mastra の RAG システムにおける検索プロセス、セマンティック検索、フィルタリング、再ランキングに関するガイド。
- [ベクトルデータベースに埋め込みを保存する | Mastra ドキュメント](https://mastra.ai/ja/docs/rag/vector-databases): Mastraにおけるベクトルストレージオプションのガイド。類似性検索のための埋め込みベクトルデータベースと専用ベクトルデータベースを含む。
- [Mastraのストレージ | Mastra ドキュメント](https://mastra.ai/ja/docs/storage/overview): Mastraのストレージシステムとデータ永続性機能の概要。
- [Mastraの音声機能 | Mastra ドキュメント](https://mastra.ai/ja/docs/voice/overview): Mastraの音声機能の概要。テキスト読み上げ、音声認識、リアルタイム音声変換などを含みます。
- [Mastraにおける音声対音声機能 | Mastra Docs](https://mastra.ai/ja/docs/voice/speech-to-speech): Mastraにおける音声対音声機能の概要（リアルタイム対話とイベント駆動型アーキテクチャを含む）。
- [Mastraにおける音声認識 (STT) | Mastra ドキュメント](https://mastra.ai/ja/docs/voice/speech-to-text): Mastraにおける音声認識機能の概要、設定、使用法、音声プロバイダーとの統合について。
- [Mastraのテキスト読み上げ (TTS) | Mastra ドキュメント](https://mastra.ai/ja/docs/voice/text-to-speech): Mastraにおけるテキスト読み上げ機能の概要、設定、使用法、音声プロバイダーとの統合について。
- [Mastraにおける音声対音声機能 | Mastra ドキュメント](https://mastra.ai/ja/docs/voice/voice-to-voice): Mastraにおける音声対音声機能の概要、リアルタイムの対話とイベント駆動型アーキテクチャを含む。
- [分岐、マージ、条件 | ワークフロー | Mastra ドキュメント](https://mastra.ai/ja/docs/workflows/control-flow): Mastraワークフローの制御フローでは、分岐、マージ、条件を管理して、ロジック要件を満たすワークフローを構築することができます。
- [動的ワークフロー | Mastra ドキュメント](https://mastra.ai/ja/docs/workflows/dynamic-workflows): ワークフローステップ内で動的ワークフローを作成する方法を学び、実行時の条件に基づいて柔軟なワークフロー作成を可能にします。
- [ワークフローにおけるエラー処理 | Mastra ドキュメント](https://mastra.ai/ja/docs/workflows/error-handling): ステップの再試行、条件分岐、モニタリングを使用して、Mastra ワークフローでエラーを処理する方法を学びます。
- [nested-workflows](https://mastra.ai/ja/docs/workflows/nested-workflows)
- [複雑なLLM操作の処理 | ワークフロー | Mastra](https://mastra.ai/ja/docs/workflows/overview): Mastraのワークフローは、分岐、並列実行、リソースの一時停止などの機能を使用して、複雑な操作のシーケンスを調整するのに役立ちます。
- [ステップの作成とワークフローへの追加 | Mastra ドキュメント](https://mastra.ai/ja/docs/workflows/steps): Mastra ワークフローのステップは、入力、出力、および実行ロジックを定義することによって、操作を管理するための構造化された方法を提供します。
- [ワークフローの一時停止と再開 | Human-in-the-Loop | Mastra ドキュメント](https://mastra.ai/ja/docs/workflows/suspend-and-resume): Mastra ワークフローでの一時停止と再開は、外部からの入力やリソースを待っている間に実行を一時停止することを可能にします。
- [ワークフローバリアブルを使用したデータマッピング | Mastra ドキュメント](https://mastra.ai/ja/docs/workflows/variables): ワークフローバリアブルを使用して、ステップ間でデータをマッピングし、Mastra ワークフローで動的なデータフローを作成する方法を学びます。
- [例：音声機能の追加 | エージェント | Mastra](https://mastra.ai/ja/examples/agents/adding-voice-capabilities): Mastraエージェントに音声機能を追加する例で、さまざまな音声プロバイダーを使用して話したり聞いたりする機能を有効にします。
- [例：エージェントワークフローの呼び出し | エージェント | Mastra ドキュメント](https://mastra.ai/ja/examples/agents/agentic-workflows): Mastraでのエージェントワークフローの作成例。LLM駆動の計画と外部APIの統合を示しています。
- [例：鳥の分類 | エージェント | Mastra ドキュメント](https://mastra.ai/ja/examples/agents/bird-checker): Unsplashからの画像が鳥を描写しているかどうかを判断するためにMastra AIエージェントを使用する例。
- [例: 階層的マルチエージェントシステム | エージェント | Mastra](https://mastra.ai/ja/examples/agents/hierarchical-multi-agent): Mastraを使用して、エージェントがツール機能を通じて相互作用する階層的マルチエージェントシステムを作成する例。
- [例：マルチエージェントワークフロー | エージェント | Mastra ドキュメント](https://mastra.ai/ja/examples/agents/multi-agent-workflow): Mastraでエージェントワークフローを作成する例で、作業成果物が複数のエージェント間で受け渡しされます。
- [例：システムプロンプトを持つエージェント | エージェント | Mastra ドキュメント](https://mastra.ai/ja/examples/agents/system-prompt): Mastraでシステムプロンプトを使用してAIエージェントの性格と能力を定義する例。
- [例：エージェントにツールを与える | エージェント | Mastra ドキュメント](https://mastra.ai/ja/examples/agents/using-a-tool): Mastraで天気情報を提供するための専用ツールを使用するAIエージェントを作成する例。
- [例：回答の関連性 | 評価 | Mastra ドキュメント](https://mastra.ai/ja/examples/evals/answer-relevancy): 回答の関連性メトリックを使用してクエリに対する応答の関連性を評価する例。
- [例：バイアス | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/bias): バイアスメトリックを使用して、さまざまな形式のバイアスに対する応答を評価する例。
- [例：完全性 | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/completeness): 完全性メトリックを使用して、レスポンスが入力要素をどれだけ徹底的にカバーしているかを評価する例。
- [例：コンテンツ類似性 | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/content-similarity): コンテンツ間のテキスト類似性を評価するためのコンテンツ類似性メトリックの使用例。
- [例：コンテキスト位置 | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/context-position): レスポンスの順序付けを評価するためのコンテキスト位置メトリックの使用例。
- [例：コンテキスト精度 | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/context-precision): コンテキスト情報がどれだけ正確に使用されているかを評価するためのコンテキスト精度メトリックの使用例。
- [例：コンテキスト関連性 | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/context-relevancy): クエリに対してコンテキスト情報がどれだけ関連しているかを評価するためのコンテキスト関連性メトリックの使用例。
- [例：文脈的リコール | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/contextual-recall): 文脈的リコール指標を使用して、レスポンスがコンテキスト情報をどれだけうまく取り入れているかを評価する例。
- [例：カスタム評価 | 評価 | Mastra ドキュメント](https://mastra.ai/ja/examples/evals/custom-eval): MastraでカスタムのLLMベース評価指標を作成する例。
- [例：忠実性 | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/faithfulness): 忠実性メトリックを使用して、レスポンスが文脈と比較してどれだけ事実に基づいているかを評価する例。
- [例：幻覚 | 評価 | Mastra ドキュメント](https://mastra.ai/ja/examples/evals/hallucination): 回答における事実の矛盾を評価するための幻覚メトリックの使用例。
- [例：キーワードカバレッジ | 評価 | Mastra ドキュメント](https://mastra.ai/ja/examples/evals/keyword-coverage): 入力テキストから重要なキーワードをレスポンスがどれだけカバーしているかを評価するためのキーワードカバレッジメトリックの使用例。
- [例：プロンプトアライメント | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/prompt-alignment): プロンプトアライメント指標を使用して、回答における指示の遵守を評価する例。
- [例：要約 | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/summarization): 要約メトリックを使用して、LLMが生成した要約がどれだけ内容を捉えながら事実の正確性を維持しているかを評価する例。
- [例：テキスト差分 | 評価 | Mastra ドキュメント](https://mastra.ai/ja/examples/evals/textual-difference): テキスト差分メトリックを使用して、シーケンスの違いや変更を分析することにより、テキスト文字列間の類似性を評価する例。
- [例：トーンの一貫性 | 評価 | Mastra ドキュメント](https://mastra.ai/ja/examples/evals/tone-consistency): トーンの一貫性メトリックを使用して、テキスト内の感情的なトーンパターンと感情の一貫性を評価する例。
- [例：有害性 | 評価 | Mastra ドキュメント](https://mastra.ai/ja/examples/evals/toxicity): 有害なコンテンツや有毒な言語に対する応答を評価するために有害性メトリックを使用する例。
- [例：単語の包含 | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/word-inclusion): 出力テキストにおける単語の包含を評価するためのカスタムメトリクスの作成例。
- [例一覧：ワークフロー、エージェント、RAG | Mastra Docs](https://mastra.ai/ja/examples): Mastraを使ったAI開発の実用的な例を探索してください。テキスト生成、RAG実装、構造化された出力、マルチモーダルインタラクションなどが含まれます。OpenAI、Anthropic、Google Geminiを使用してAIアプリケーションを構築する方法を学びましょう。
- [メモリプロセッサ](https://mastra.ai/ja/examples/memory/memory-processors): 呼び出されたメッセージをフィルタリングおよび変換するためのメモリプロセッサの使用例
- [memory-with-libsql](https://mastra.ai/ja/examples/memory/memory-with-libsql)
- [memory-with-pg](https://mastra.ai/ja/examples/memory/memory-with-pg)
- [memory-with-upstash](https://mastra.ai/ja/examples/memory/memory-with-upstash)
- [ストリーミング作業記憶（上級）](https://mastra.ai/ja/examples/memory/streaming-working-memory-advanced): 会話を通じてToDoリストを維持するための作業記憶の使用例
- [ストリーミング作業メモリ](https://mastra.ai/ja/examples/memory/streaming-working-memory): エージェントで作業メモリを使用する例
- [AI SDK useChat フック](https://mastra.ai/ja/examples/memory/use-chat): Mastra メモリを Vercel AI SDK useChat フックと統合する方法を示す例。
- [例：チャンクデリミタの調整 | RAG | Mastra ドキュメント](https://mastra.ai/ja/examples/rag/chunking/adjust-chunk-delimiters): Mastraでチャンクデリミタを調整して、コンテンツ構造により適合させる方法。
- [例：チャンクサイズの調整 | RAG | Mastra ドキュメント](https://mastra.ai/ja/examples/rag/chunking/adjust-chunk-size): Mastraでチャンクサイズを調整して、コンテンツとメモリ要件により適合させます。
- [例：HTMLのセマンティックチャンキング | RAG | Mastra ドキュメント](https://mastra.ai/ja/examples/rag/chunking/chunk-html): MastraでドキュメントをセマンティックにチャンクするためにHTMLコンテンツをチャンクする。
- [例：JSONのセマンティックチャンキング | RAG | Mastra ドキュメント](https://mastra.ai/ja/examples/rag/chunking/chunk-json): MastraでセマンティックにドキュメントをチャンクするためのJSONデータのチャンキング。
- [例：マークダウンのセマンティックチャンキング | RAG | Mastra ドキュメント](https://mastra.ai/ja/examples/rag/chunking/chunk-markdown): 検索や取得目的でマークダウン文書をチャンク化するためのMastraの使用例。
- [例：テキストの意味的チャンキング | RAG | Mastra ドキュメント](https://mastra.ai/ja/examples/rag/chunking/chunk-text): 大きなテキスト文書を処理のために小さなチャンクに分割するためのMastraの使用例。
- [例：チャンク配列の埋め込み | RAG | Mastra ドキュメント](https://mastra.ai/ja/examples/rag/embedding/embed-chunk-array): 類似性検索のためにテキストチャンクの配列の埋め込みを生成するためにMastraを使用する例。
- [例：テキストチャンクの埋め込み | RAG | Mastra ドキュメント](https://mastra.ai/ja/examples/rag/embedding/embed-text-chunk): 類似性検索のために単一のテキストチャンクの埋め込みを生成するためにMastraを使用する例。
- [例: Cohereを使用したテキストの埋め込み | RAG | Mastra ドキュメント](https://mastra.ai/ja/examples/rag/embedding/embed-text-with-cohere): Cohereの埋め込みモデルを使用して埋め込みを生成するMastraの使用例。
- [例：メタデータ抽出 | 検索 | RAG | Mastra ドキュメント](https://mastra.ai/ja/examples/rag/embedding/metadata-extraction): Mastraでドキュメントからメタデータを抽出して活用する例。ドキュメント処理と検索を強化します。
- [例：ハイブリッドベクトル検索 | RAG | Mastra ドキュメント](https://mastra.ai/ja/examples/rag/query/hybrid-vector-search): Mastraでベクトル検索結果を強化するためにPGVectorでメタデータフィルターを使用する例。
- [例：トップK結果の取得 | RAG | Mastra ドキュメント](https://mastra.ai/ja/examples/rag/query/retrieve-results): Mastraを使用してベクトルデータベースをクエリし、意味的に類似したチャンクを取得する例。
- [例: ツールを使用した結果の再ランク付け | 検索 | RAG | Mastra ドキュメント](https://mastra.ai/ja/examples/rag/rerank/rerank-rag): OpenAI埋め込みとベクトルストレージにPGVectorを使用して、Mastraで再ランク付けを行うRAGシステムを実装する例。
- [例: 結果の再ランク付け | 検索 | RAG | Mastra ドキュメント](https://mastra.ai/ja/examples/rag/rerank/rerank): OpenAI埋め込みとベクトル保存のためのPGVectorを使用して、Mastraでセマンティック再ランク付けを実装する例。
- [例: Cohereを使用したリランキング | RAG | Mastra ドキュメント](https://mastra.ai/ja/examples/rag/rerank/reranking-with-cohere): Cohereのリランキングサービスを使用して、Mastraでドキュメント検索の関連性を向上させる例。
- [例：埋め込みのアップサート | RAG | Mastra ドキュメント](https://mastra.ai/ja/examples/rag/upsert/upsert-embeddings): 類似性検索のために様々なベクトルデータベースに埋め込みを保存するMastraの使用例。
- [例：ベクトルクエリツールの使用 | RAG | Mastra ドキュメント](https://mastra.ai/ja/examples/rag/usage/basic-rag): OpenAI埋め込みとベクトルストレージにPGVectorを使用して、Mastraで基本的なRAGシステムを実装する例。
- [例：情報密度の最適化 | RAG | Mastra ドキュメント](https://mastra.ai/ja/examples/rag/usage/cleanup-rag): Mastraでのデータ重複排除とLLMベースの処理を使用して情報密度を最適化するRAGシステムの実装例。
- [例：思考の連鎖プロンプティング | RAG | Mastra ドキュメント](https://mastra.ai/ja/examples/rag/usage/cot-rag): OpenAIとPGVectorを使用した思考の連鎖推論によるMastraでのRAGシステム実装の例。
- [例：ワークフローを使用した構造化推論 | RAG | Mastra ドキュメント](https://mastra.ai/ja/examples/rag/usage/cot-workflow-rag): Mastraのワークフロー機能を使用してRAGシステムに構造化推論を実装する例。
- [例: エージェント駆動のメタデータフィルタリング | 検索 | RAG | Mastra ドキュメント](https://mastra.ai/ja/examples/rag/usage/filter-rag): RAG システムで Mastra エージェントを使用して、ドキュメント検索のためのメタデータフィルターを構築および適用する例。
- [例: 完全なグラフRAGシステム | RAG | Mastraドキュメント](https://mastra.ai/ja/examples/rag/usage/graph-rag): OpenAI埋め込みとベクトルストレージにPGVectorを使用して、MastraでグラフRAGシステムを実装する例。
- [例: 音声からテキストへ | 音声 | Mastra ドキュメント](https://mastra.ai/ja/examples/voice/speech-to-text): Mastraを使用して音声からテキストへの変換アプリケーションを作成する例。
- [例: テキスト読み上げ | 音声 | Mastra ドキュメント](https://mastra.ai/ja/examples/voice/text-to-speech): Mastraを使用してテキスト読み上げアプリケーションを作成する例。
- [例：分岐パス | ワークフロー | Mastra ドキュメント](https://mastra.ai/ja/examples/workflows/branching-paths): 中間結果に基づいて分岐パスを持つワークフローを作成するためのMastraの使用例。
- [例：ワークフローからエージェントを呼び出す | Mastra ドキュメント](https://mastra.ai/ja/examples/workflows/calling-agent): ワークフローステップ内からAIエージェントを呼び出すためのMastraの使用例。
- [例：条件分岐（実験的） | ワークフロー | Mastra ドキュメント](https://mastra.ai/ja/examples/workflows/conditional-branching): if/else文を使用してワークフローに条件分岐を作成するためのMastraの使用例。
- [例：ワークフローの作成 | ワークフロー | Mastra ドキュメント](https://mastra.ai/ja/examples/workflows/creating-a-workflow): Mastraを使用して単一ステップの簡単なワークフローを定義し実行する例。
- [例：循環依存関係 | ワークフロー | Mastra ドキュメント](https://mastra.ai/ja/examples/workflows/cyclical-dependencies): 循環依存関係と条件付きループを持つワークフローを作成するためのMastraの使用例。
- [例：ヒューマン・イン・ザ・ループ | ワークフロー | Mastra ドキュメント](https://mastra.ai/ja/examples/workflows/human-in-the-loop): 人間の介入ポイントを含むワークフローを作成するためのMastraの使用例。
- [例：並列実行 | ワークフロー | Mastra ドキュメント](https://mastra.ai/ja/examples/workflows/parallel-steps): Mastraを使用してワークフロー内で複数の独立したタスクを並列実行する例。
- [例：順次ステップ | ワークフロー | Mastra ドキュメント](https://mastra.ai/ja/examples/workflows/sequential-steps): データを受け渡しながら、特定の順序でワークフローステップを連鎖させるMastraの使用例。
- [例：一時停止と再開 | ワークフロー | Mastra ドキュメント](https://mastra.ai/ja/examples/workflows/suspend-and-resume): Mastraを使用して実行中にワークフローステップを一時停止および再開する例。
- [例：ツールをステップとして使用する | ワークフロー | Mastra ドキュメント](https://mastra.ai/ja/examples/workflows/using-a-tool-as-a-step): カスタムツールをワークフローのステップとして統合するためにMastraを使用する例。
- [ワークフロー変数を使用したデータマッピング | Mastraの例](https://mastra.ai/ja/examples/workflows/workflow-variables): Mastraワークフローでステップ間のデータをマッピングするためにワークフロー変数を使用する方法を学びます。
- [AI採用担当者の構築 | Mastraワークフロー | ガイド](https://mastra.ai/ja/guides/guide/ai-recruiter): LLMを使用して候補者情報を収集・処理するMastraでの採用担当者ワークフローの構築ガイド。
- [AIシェフアシスタントの構築 | Mastraエージェントガイド](https://mastra.ai/ja/guides/guide/chef-michel): 利用可能な食材で料理を作るユーザーを支援するMastraでのシェフアシスタントエージェントの作成ガイド。
- [研究論文アシスタントの構築 | Mastra RAG ガイド](https://mastra.ai/ja/guides/guide/research-assistant): RAGを使用して学術論文を分析し、質問に答えるAI研究アシスタントを作成するためのガイド。
- [AI株式エージェントの構築 | Mastraエージェント | ガイド](https://mastra.ai/ja/guides/guide/stock-agent): 指定された銘柄の前日終値を取得するシンプルな株式エージェントをMastraで作成するガイド。
- [概要](https://mastra.ai/ja/guides): Mastraを使った構築ガイド
- [リファレンス: createTool() | ツール | エージェント | Mastra ドキュメント](https://mastra.ai/ja/reference/agents/createTool): MastraのcreateTool関数に関するドキュメントで、エージェントとワークフローのためのカスタムツールを作成します。
- [リファレンス: Agent.generate() | Agents | Mastra ドキュメント](https://mastra.ai/ja/reference/agents/generate): Mastra エージェントの `.generate()` メソッドに関するドキュメントで、テキストまたは構造化された応答を生成します。
- [リファレンス: getAgent() | エージェント設定 | エージェント | Mastra ドキュメント](https://mastra.ai/ja/reference/agents/getAgent): getAgent の API リファレンス。
- [リファレンス: Agent.stream() | ストリーミング | エージェント | Mastra ドキュメント](https://mastra.ai/ja/reference/agents/stream): Mastraエージェントの`.stream()`メソッドに関するドキュメント。リアルタイムでのレスポンスのストリーミングを可能にします。
- [mastra build](https://mastra.ai/ja/reference/cli/build): Mastraプロジェクトを本番環境にデプロイするためにビルドします
- [`mastra dev` リファレンス | ローカル開発 | Mastra CLI](https://mastra.ai/ja/reference/cli/dev): エージェント、ツール、ワークフローの開発サーバーを起動するmastra devコマンドのドキュメント。
- [`mastra init` リファレンス | プロジェクト作成 | Mastra CLI](https://mastra.ai/ja/reference/cli/init): インタラクティブなセットアップオプションで新しいMastraプロジェクトを作成する「mastra init」コマンドのドキュメント。
- [agents](https://mastra.ai/ja/reference/client-js/agents)
- [error-handling](https://mastra.ai/ja/reference/client-js/error-handling)
- [logs](https://mastra.ai/ja/reference/client-js/logs)
- [memory](https://mastra.ai/ja/reference/client-js/memory)
- [telemetry](https://mastra.ai/ja/reference/client-js/telemetry)
- [tools](https://mastra.ai/ja/reference/client-js/tools)
- [vectors](https://mastra.ai/ja/reference/client-js/vectors)
- [workflows](https://mastra.ai/ja/reference/client-js/workflows)
- [Mastra Core](https://mastra.ai/ja/reference/core/mastra-class): エージェント、ワークフロー、サーバーエンドポイントを管理するためのコアエントリーポイントであるMastraクラスのドキュメント。
- [Cloudflare Deployer](https://mastra.ai/ja/reference/deployer/cloudflare): CloudflareDeployerクラスのドキュメント。MastraアプリケーションをCloudflare Workersにデプロイします。
- [Mastra デプロイヤー](https://mastra.ai/ja/reference/deployer/deployer): Mastraアプリケーションのパッケージングとデプロイを処理する、Deployer抽象クラスのドキュメント。
- [Netlify デプロイヤー](https://mastra.ai/ja/reference/deployer/netlify): NetlifyDeployer クラスのドキュメントで、Mastra アプリケーションを Netlify Functions にデプロイします。
- [Vercel デプロイヤー](https://mastra.ai/ja/reference/deployer/vercel): Mastraアプリケーションを Vercel にデプロイする VercelDeployer クラスのドキュメント。
- [リファレンス: 回答の関連性 | メトリクス | 評価 | Mastra ドキュメント](https://mastra.ai/ja/reference/evals/answer-relevancy): Mastraにおける回答関連性メトリクスのドキュメント。LLM出力がどれだけ適切に入力クエリに対応しているかを評価します。
- [リファレンス: バイアス | 出力メトリクス | 評価 | Mastra ドキュメント](https://mastra.ai/ja/reference/evals/bias): Mastraのバイアスメトリクスに関するドキュメント。LLMの出力における性別、政治的、人種/民族的、または地理的バイアスなど、さまざまな形態のバイアスを評価します。
- [リファレンス: 完全性 | メトリクス | 評価 | Mastra ドキュメント](https://mastra.ai/ja/reference/evals/completeness): Mastraの完全性メトリクスに関するドキュメント。LLM出力が入力に含まれる重要な要素をどれだけ網羅しているかを評価します。
- [リファレンス: コンテンツ類似性 | Evals | Mastra Docs](https://mastra.ai/ja/reference/evals/content-similarity): Mastraのコンテンツ類似性メトリックに関するドキュメント。文字列間のテキスト類似性を測定し、マッチングスコアを提供します。
- [リファレンス: コンテキスト位置 | メトリクス | Evals | Mastra ドキュメント](https://mastra.ai/ja/reference/evals/context-position): Mastraにおけるコンテキスト位置メトリクスのドキュメントで、クエリと出力に対する関連性に基づいてコンテキストノードの順序を評価します。
- [リファレンス: コンテキスト精度 | メトリクス | Evals | Mastra ドキュメント](https://mastra.ai/ja/reference/evals/context-precision): 期待される出力を生成するために取得されたコンテキストノードの関連性と精度を評価する、Mastra のコンテキスト精度メトリクスに関するドキュメント。
- [リファレンス: コンテキストの関連性 | Evals | Mastra Docs](https://mastra.ai/ja/reference/evals/context-relevancy): RAGパイプラインで取得されたコンテキストの関連性を評価するコンテキスト関連性メトリックのドキュメント。
- [リファレンス：文脈的再現性 | メトリクス | 評価 | Mastra ドキュメント](https://mastra.ai/ja/reference/evals/contextual-recall): 文脈的再現性メトリックのドキュメント。これはLLMの応答が関連する文脈をどれだけ完全に取り入れているかを評価します。
- [リファレンス: Faithfulness | メトリクス | Evals | Mastra ドキュメント](https://mastra.ai/ja/reference/evals/faithfulness): 提供されたコンテキストと比較して、LLM出力の事実の正確性を評価するMastraのFaithfulnessメトリクスのドキュメント。
- [リファレンス: 幻覚 | メトリクス | Evals | Mastra ドキュメント](https://mastra.ai/ja/reference/evals/hallucination): 提供されたコンテキストと矛盾する点を特定することで、LLM出力の事実の正確性を評価するMastraの幻覚メトリクスに関するドキュメント。
- [リファレンス: キーワードカバレッジ | メトリクス | 評価 | Mastra ドキュメント](https://mastra.ai/ja/reference/evals/keyword-coverage): Mastraのキーワードカバレッジメトリクスに関するドキュメント。LLMの出力が入力からの重要なキーワードをどれだけカバーしているかを評価します。
- [リファレンス: プロンプトアライメント | メトリクス | 評価 | Mastra ドキュメント](https://mastra.ai/ja/reference/evals/prompt-alignment): Mastraのプロンプトアライメントメトリクスに関するドキュメント。LLMの出力が与えられたプロンプト指示にどれだけ忠実に従っているかを評価します。
- [リファレンス: 要約 | メトリクス | Evals | Mastra ドキュメント](https://mastra.ai/ja/reference/evals/summarization): Mastraにおける要約メトリクスのドキュメントで、コンテンツと事実の正確性に関するLLM生成要約の品質を評価します。
- [リファレンス: テキスト差分 | Evals | Mastra ドキュメント](https://mastra.ai/ja/reference/evals/textual-difference): Mastraにおけるテキスト差分メトリックのドキュメントで、シーケンスマッチングを使用して文字列間のテキスト差分を測定します。
- [リファレンス: トーンの一貫性 | メトリクス | Evals | Mastra ドキュメント](https://mastra.ai/ja/reference/evals/tone-consistency): Mastraにおけるトーンの一貫性メトリクスのドキュメントで、テキストの感情的トーンと感情の一貫性を評価します。
- [リファレンス: 有害性 | メトリクス | Evals | Mastra ドキュメント](https://mastra.ai/ja/reference/evals/toxicity): Mastraにおける有害性メトリクスのドキュメントで、人種差別的、偏見的、または有害な要素を含むLLM出力を評価します。
- [API リファレンス](https://mastra.ai/ja/reference): Mastra API リファレンス
- [Memory](https://mastra.ai/ja/reference/memory/Memory)
- [createThread](https://mastra.ai/ja/reference/memory/createThread)
- [getThreadById](https://mastra.ai/ja/reference/memory/getThreadById)
- [getThreadsByResourceId](https://mastra.ai/ja/reference/memory/getThreadsByResourceId)
- [query](https://mastra.ai/ja/reference/memory/query)
- [AgentNetwork（実験的）](https://mastra.ai/ja/reference/networks/agent-network): AgentNetworkクラスのリファレンスドキュメント
- [リファレンス: createLogger() | Mastra Observability ドキュメント](https://mastra.ai/ja/reference/observability/create-logger): 指定された設定に基づいてロガーをインスタンス化する createLogger 関数のドキュメント。
- [リファレンス: Logger インスタンス | Mastra Observability ドキュメント](https://mastra.ai/ja/reference/observability/logger): 様々な重大度レベルでイベントを記録するためのメソッドを提供する Logger インスタンスのドキュメント。
- [リファレンス: OtelConfig | Mastra Observability ドキュメント](https://mastra.ai/ja/reference/observability/otel-config): OpenTelemetry の計装、トレース、およびエクスポートの動作を設定する OtelConfig オブジェクトのドキュメント。
- [リファレンス: Braintrust | 観測性 | Mastra ドキュメント](https://mastra.ai/ja/reference/observability/providers/braintrust): BraintrustをMastraと統合するためのドキュメント。MastraはLLMアプリケーションの評価と監視プラットフォームです。
- [リファレンス: Dash0 統合 | Mastra オブザーバビリティ ドキュメント](https://mastra.ai/ja/reference/observability/providers/dash0): MastraとDash0、Open Telementryネイティブのオブザーバビリティソリューションとの統合に関するドキュメント。
- [リファレンス: プロバイダーリスト | オブザーバビリティ | Mastra ドキュメント](https://mastra.ai/ja/reference/observability/providers): Dash0、SigNoz、Braintrust、Langfuse など、Mastra がサポートするオブザーバビリティプロバイダーの概要。
- [リファレンス: Laminar 統合 | Mastra 観測性ドキュメント](https://mastra.ai/ja/reference/observability/providers/laminar): LLMアプリケーション向けの専門的な観測性プラットフォームであるMastraとLaminarを統合するためのドキュメント。
- [リファレンス: Langfuse 統合 | Mastra オブザーバビリティ ドキュメント](https://mastra.ai/ja/reference/observability/providers/langfuse): LLM アプリケーション向けのオープンソースオブザーバビリティプラットフォームである Mastra と Langfuse を統合するためのドキュメント。
- [リファレンス: LangSmith 統合 | Mastra オブザーバビリティ ドキュメント](https://mastra.ai/ja/reference/observability/providers/langsmith): LLMアプリケーションのデバッグ、テスト、評価、監視のためのプラットフォームであるMastraとLangSmithを統合するためのドキュメント。
- [リファレンス: LangWatch 統合 | Mastra オブザーバビリティ ドキュメント](https://mastra.ai/ja/reference/observability/providers/langwatch): LLMアプリケーション向けの専門的なオブザーバビリティプラットフォームであるMastraとLangWatchの統合に関するドキュメント。
- [リファレンス: New Relic 統合 | Mastra オブザーバビリティ ドキュメント](https://mastra.ai/ja/reference/observability/providers/new-relic): New Relic と Mastra の統合に関するドキュメント。Mastra は、OpenTelemetry をサポートするフルスタック監視のための包括的なオブザーバビリティ プラットフォームです。
- [リファレンス: SigNoz 統合 | Mastra オブザーバビリティ ドキュメント](https://mastra.ai/ja/reference/observability/providers/signoz): SigNozをMastraと統合するためのドキュメント。Mastraは、OpenTelemetryを通じてフルスタック監視を提供するオープンソースのAPMおよびオブザーバビリティプラットフォームです。
- [リファレンス: Traceloop 統合 | Mastra 観測性ドキュメント](https://mastra.ai/ja/reference/observability/providers/traceloop): Traceloop を Mastra と統合するためのドキュメント。Mastra は LLM アプリケーション向けの OpenTelemetry ネイティブの観測性プラットフォームです。
- [リファレンス: Astra Vector Store | ベクターデータベース | RAG | Mastra ドキュメント](https://mastra.ai/ja/reference/rag/astra): DataStax Astra DBを使用したベクター検索を提供するMastraのAstraVectorクラスのドキュメント。
- [リファレンス: Chroma Vector Store | ベクターデータベース | RAG | Mastra ドキュメント](https://mastra.ai/ja/reference/rag/chroma): MastraのChromaVectorクラスのドキュメントで、ChromaDBを使用したベクター検索を提供します。
- [リファレンス: .chunk() | ドキュメント処理 | RAG | Mastra ドキュメント](https://mastra.ai/ja/reference/rag/chunk): Mastraのchunk関数のドキュメントで、さまざまな戦略を使用してドキュメントを小さなセグメントに分割します。
- [リファレンス: MDocument | ドキュメント処理 | RAG | Mastra Docs](https://mastra.ai/ja/reference/rag/document): MastraのMDocumentクラスのドキュメントで、ドキュメントの処理とチャンク化を扱います。
- [リファレンス: embed() | ドキュメント埋め込み | RAG | Mastra ドキュメント](https://mastra.ai/ja/reference/rag/embeddings): MastraでAI SDKを使用した埋め込み機能のドキュメント。
- [リファレンス: ExtractParams | ドキュメント処理 | RAG | Mastra ドキュメント](https://mastra.ai/ja/reference/rag/extract-params): Mastraにおけるメタデータ抽出設定のドキュメント。
- [リファレンス: GraphRAG | グラフベースのRAG | RAG | Mastra ドキュメント](https://mastra.ai/ja/reference/rag/graph-rag): MastraのGraphRAGクラスのドキュメントで、グラフベースのアプローチを用いたリトリーバル拡張生成を実装しています。
- [デフォルトベクターストア | ベクターデータベース | RAG | Mastra ドキュメント](https://mastra.ai/ja/reference/rag/libsql): LibSQLのベクター拡張を使用してベクター検索を提供するMastraのLibSQLVectorクラスのドキュメント。
- [リファレンス: メタデータフィルター | メタデータフィルタリング | RAG | Mastra ドキュメント](https://mastra.ai/ja/reference/rag/metadata-filters): Mastraにおけるメタデータフィルタリング機能のドキュメントで、異なるベクトルストアにわたるベクトル検索結果の正確なクエリを可能にします。
- [リファレンス: PG Vector Store | ベクターデータベース | RAG | Mastra ドキュメント](https://mastra.ai/ja/reference/rag/pg): PostgreSQLのpgvector拡張機能を使用してベクター検索を提供するMastraのPgVectorクラスのドキュメント。
- [リファレンス: Pinecone Vector Store | Vector DBs | RAG | Mastra ドキュメント](https://mastra.ai/ja/reference/rag/pinecone): MastraのPineconeVectorクラスのドキュメントで、Pineconeのベクターデータベースへのインターフェースを提供します。
- [リファレンス: Qdrant ベクターストア | ベクターデータベース | RAG | Mastra ドキュメント](https://mastra.ai/ja/reference/rag/qdrant): ベクターとペイロードを管理するためのベクター類似検索エンジンであるQdrantをMastraと統合するためのドキュメント。
- [リファレンス: Rerank | ドキュメント検索 | RAG | Mastra Docs](https://mastra.ai/ja/reference/rag/rerank): Mastraのrerank関数のドキュメントで、ベクター検索結果の高度な再ランキング機能を提供します。
- [リファレンス: Turbopuffer ベクターストア | ベクターデータベース | RAG | Mastra ドキュメント](https://mastra.ai/ja/reference/rag/turbopuffer): TurbopufferをMastraと統合するためのドキュメント。効率的な類似検索のための高性能ベクターデータベース。
- [リファレンス: Upstash Vector Store | ベクターデータベース | RAG | Mastra ドキュメント](https://mastra.ai/ja/reference/rag/upstash): MastraのUpstashVectorクラスのドキュメントで、Upstash Vectorを使用したベクター検索を提供します。
- [リファレンス: Cloudflare Vector Store | ベクターデータベース | RAG | Mastra ドキュメント](https://mastra.ai/ja/reference/rag/vectorize): Cloudflare Vectorizeを使用したベクター検索を提供するMastraのCloudflareVectorクラスのドキュメント。
- [LibSQL ストレージ | ストレージシステム | Mastra Core](https://mastra.ai/ja/reference/storage/libsql): MastraにおけるLibSQLストレージ実装のドキュメント。
- [PostgreSQL ストレージ | ストレージシステム | Mastra Core](https://mastra.ai/ja/reference/storage/postgresql): MastraにおけるPostgreSQLストレージ実装のドキュメント。
- [Upstash Storage | ストレージシステム | Mastra Core](https://mastra.ai/ja/reference/storage/upstash): MastraにおけるUpstashストレージ実装のドキュメント。
- [リファレンス: MastraMCPClient | ツールディスカバリー | Mastra ドキュメント](https://mastra.ai/ja/reference/tools/client): MastraMCPClient の API リファレンス - モデルコンテキストプロトコルのクライアント実装。
- [リファレンス: createDocumentChunkerTool() | ツール | Mastra ドキュメント](https://mastra.ai/ja/reference/tools/document-chunker-tool): Mastraのドキュメントチャンクツールのドキュメントで、効率的な処理と取得のためにドキュメントを小さなチャンクに分割します。
- [リファレンス: createGraphRAGTool() | RAG | Mastra Tools ドキュメント](https://mastra.ai/ja/reference/tools/graph-rag-tool): MastraのGraph RAG Toolのドキュメントで、ドキュメント間のセマンティック関係のグラフを構築することでRAGを強化します。
- [リファレンス: MCPConfiguration | ツール管理 | Mastra ドキュメント](https://mastra.ai/ja/reference/tools/mcp-configuration): MCPConfiguration の API リファレンス - 複数のモデルコンテキストプロトコルサーバーとそのツールを管理するためのクラス。
- [リファレンス: createVectorQueryTool() | RAG | Mastra Tools ドキュメント](https://mastra.ai/ja/reference/tools/vector-query-tool): ベクトルストア上でのフィルタリングと再ランキング機能を備えたセマンティック検索を可能にするMastraのベクトルクエリツールのドキュメント。
- [リファレンス: Azure Voice | 音声プロバイダー | Mastra ドキュメント](https://mastra.ai/ja/reference/voice/azure): Azure Cognitive Servicesを使用してテキスト読み上げと音声認識機能を提供するAzureVoiceクラスのドキュメント。
- [リファレンス: Cloudflare Voice | 音声プロバイダー | Mastra ドキュメント](https://mastra.ai/ja/reference/voice/cloudflare): CloudflareVoiceクラスのドキュメント。Cloudflare Workers AIを使用したテキスト読み上げ機能を提供します。
- [リファレンス: CompositeVoice | Voice Providers | Mastra ドキュメント](https://mastra.ai/ja/reference/voice/composite-voice): CompositeVoice クラスのドキュメントで、複数の音声プロバイダーを組み合わせて柔軟なテキスト読み上げと音声認識操作を可能にします。
- [リファレンス: Deepgram Voice | 音声プロバイダー | Mastra ドキュメント](https://mastra.ai/ja/reference/voice/deepgram): Deepgramの音声実装に関するドキュメントで、複数の音声モデルと言語を使用したテキスト読み上げと音声認識機能を提供します。
- [リファレンス: ElevenLabs Voice | 音声プロバイダー | Mastra ドキュメント](https://mastra.ai/ja/reference/voice/elevenlabs): ElevenLabs の音声実装に関するドキュメントで、複数の音声モデルと自然な音声合成を備えた高品質なテキスト読み上げ機能を提供します。
- [リファレンス: Google Voice | Voice Providers | Mastra Docs](https://mastra.ai/ja/reference/voice/google): Google Voice の実装に関するドキュメントで、テキスト読み上げと音声認識機能を提供します。
- [リファレンス: MastraVoice | ボイスプロバイダー | Mastra ドキュメント](https://mastra.ai/ja/reference/voice/mastra-voice): Mastra のすべての音声サービスのコアインターフェースを定義する MastraVoice 抽象基底クラスのドキュメントで、音声間変換機能を含みます。
- [リファレンス: Murf Voice | Voice Providers | Mastra Docs](https://mastra.ai/ja/reference/voice/murf): Murf音声実装のドキュメントで、テキスト読み上げ機能を提供します。
- [リファレンス: OpenAI リアルタイム音声 | 音声プロバイダー | Mastra ドキュメント](https://mastra.ai/ja/reference/voice/openai-realtime): OpenAIRealtimeVoice クラスのドキュメントで、WebSockets を介したリアルタイムのテキスト読み上げと音声認識機能を提供します。
- [リファレンス: OpenAI Voice | 音声プロバイダー | Mastra ドキュメント](https://mastra.ai/ja/reference/voice/openai): OpenAIVoice クラスのドキュメントで、テキストから音声への変換と音声からテキストへの変換機能を提供します。
- [リファレンス: PlayAI Voice | Voice Providers | Mastra Docs](https://mastra.ai/ja/reference/voice/playai): PlayAI音声実装のドキュメントで、テキスト読み上げ機能を提供します。
- [リファレンス: Sarvam Voice | Voice Providers | Mastra Docs](https://mastra.ai/ja/reference/voice/sarvam): Sarvamクラスのドキュメントで、テキストから音声への変換と音声からテキストへの変換機能を提供します。
- [リファレンス: Speechify Voice | Voice Providers | Mastra Docs](https://mastra.ai/ja/reference/voice/speechify): Speechify音声実装のドキュメントで、テキスト読み上げ機能を提供します。
- [リファレンス: voice.addInstructions() | 音声プロバイダー | Mastra ドキュメント](https://mastra.ai/ja/reference/voice/voice.addInstructions): 音声プロバイダーで利用可能なaddInstructions()メソッドのドキュメント。音声モデルの動作を導くための指示を追加します。
- [リファレンス: voice.addTools() | 音声プロバイダー | Mastra ドキュメント](https://mastra.ai/ja/reference/voice/voice.addTools): 音声プロバイダーで利用可能なaddTools()メソッドのドキュメント。音声モデルに関数呼び出し機能を提供します。
- [リファレンス: voice.answer() | Voice Providers | Mastra Docs](https://mastra.ai/ja/reference/voice/voice.answer): リアルタイム音声プロバイダーで利用可能な answer() メソッドのドキュメントで、音声プロバイダーに応答を生成させるトリガーです。
- [リファレンス: voice.close() | 音声プロバイダー | Mastra ドキュメント](https://mastra.ai/ja/reference/voice/voice.close): リアルタイム音声サービスから切断するための、音声プロバイダーで利用可能なclose()メソッドのドキュメント。
- [リファレンス: voice.connect() | Voice Providers | Mastra Docs](https://mastra.ai/ja/reference/voice/voice.connect): リアルタイム音声プロバイダーで利用可能なconnect()メソッドのドキュメントで、音声間通信の接続を確立します。
- [リファレンス：音声イベント | 音声プロバイダー | Mastra ドキュメント](https://mastra.ai/ja/reference/voice/voice.events): 音声プロバイダーから発信されるイベントのドキュメント、特にリアルタイム音声インタラクションに関するもの。
- [リファレンス: voice.getSpeakers() | 音声プロバイダー | Mastra ドキュメント](https://mastra.ai/ja/reference/voice/voice.getSpeakers): 音声プロバイダーで利用可能なgetSpeakers()メソッドのドキュメント。利用可能な音声オプションを取得します。
- [リファレンス: voice.listen() | Voice Providers | Mastra Docs](https://mastra.ai/ja/reference/voice/voice.listen): すべてのMastra音声プロバイダーで利用可能なlisten()メソッドのドキュメントで、音声をテキストに変換します。
- [リファレンス: voice.off() | 音声プロバイダー | Mastra ドキュメント](https://mastra.ai/ja/reference/voice/voice.off): 音声プロバイダーで利用可能なoff()メソッドのドキュメント。音声イベントのイベントリスナーを削除します。
- [リファレンス: voice.on() | Voice Providers | Mastra Docs](https://mastra.ai/ja/reference/voice/voice.on): 音声プロバイダーで利用可能な on() メソッドのドキュメントで、音声イベントのイベントリスナーを登録します。
- [リファレンス: voice.send() | Voice Providers | Mastra Docs](https://mastra.ai/ja/reference/voice/voice.send): リアルタイム音声プロバイダーで利用可能なsend()メソッドのドキュメントで、音声データをストリーミングして継続的に処理します。
- [リファレンス: voice.speak() | Voice Providers | Mastra Docs](https://mastra.ai/ja/reference/voice/voice.speak): すべてのMastra音声プロバイダーで利用可能なspeak()メソッドのドキュメントで、テキストを音声に変換します。
- [リファレンス: voice.updateConfig() | 音声プロバイダー | Mastra Docs](https://mastra.ai/ja/reference/voice/voice.updateConfig): 音声プロバイダーで利用可能なupdateConfig()メソッドのドキュメント。実行時に音声プロバイダーの設定を更新します。
- [リファレンス: .after() | ワークフローの構築 | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/after): ワークフローにおける `after()` メソッドのドキュメントで、分岐と統合のパスを可能にします。
- [.afterEvent() メソッド | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/afterEvent): イベントベースのサスペンションポイントを作成する Mastra ワークフローの afterEvent メソッドのリファレンス。
- [リファレンス: Workflow.commit() | ワークフローの実行 | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/commit): ワークフロー内の `.commit()` メソッドに関するドキュメントで、現在のステップ構成でワークフローマシンを再初期化します。
- [リファレンス: Workflow.createRun() | ワークフローの実行 | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/createRun): ワークフロー内の `.createRun()` メソッドのドキュメントで、新しいワークフロー実行インスタンスを初期化します。
- [リファレンス: Workflow.else() | 条件分岐 | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/else): Mastra ワークフローにおける `.else()` メソッドのドキュメントで、if 条件が偽の場合に代替の分岐を作成します。
- [イベント駆動型ワークフロー | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/events): MastraでafterEventメソッドとresumeWithEventメソッドを使用してイベント駆動型ワークフローを作成する方法を学びます。
- [リファレンス: Workflow.execute() | ワークフロー | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/execute): Mastra ワークフローにおける `.execute()` メソッドのドキュメントで、ワークフローステップを実行し、結果を返します。
- [リファレンス: Workflow.if() | 条件分岐 | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/if): Mastra ワークフローにおける `.if()` メソッドのドキュメントで、指定された条件に基づいて条件分岐を作成します。
- [リファレンス: run.resume() | ワークフローの実行 | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/resume): ワークフロー内の `.resume()` メソッドに関するドキュメントで、一時停止されたワークフローステップの実行を再開します。
- [.resumeWithEvent() メソッド | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/resumeWithEvent): イベントデータを使用して中断されたワークフローを再開する resumeWithEvent メソッドのリファレンス。
- [リファレンス: スナップショット | ワークフロー状態の永続化 | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/snapshots): Mastraにおけるスナップショットに関する技術リファレンス - 一時停止と再開機能を可能にするシリアライズされたワークフロー状態
- [リファレンス: start() | ワークフローの実行 | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/start): ワークフロー内の `start()` メソッドに関するドキュメントで、ワークフロー実行の開始を行います。
- [リファレンス: ステップ | ワークフローの構築 | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/step-class): ワークフロー内の個々の作業単位を定義するStepクラスのドキュメント。
- [リファレンス: StepCondition | ワークフローの構築 | Mastra](https://mastra.ai/ja/reference/workflows/step-condition): ワークフロー内のステップ条件クラスのドキュメントで、前のステップの出力やトリガーデータに基づいてステップを実行するかどうかを決定します。
- [リファレンス: Workflow.step() | ワークフロー | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/step-function): ワークフロー内の `.step()` メソッドに関するドキュメントで、ワークフローに新しいステップを追加します。
- [リファレンス: StepOptions | ワークフローの構築 | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/step-options): ワークフロー内のステップオプションに関するドキュメントで、変数マッピング、実行条件、その他のランタイム動作を制御します。
- [ステップのリトライ | エラーハンドリング | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/step-retries): 設定可能なリトライポリシーで、Mastra ワークフロー内の失敗したステップを自動的にリトライします。
- [リファレンス: suspend() | 制御フロー | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/suspend): Mastra ワークフローにおける suspend 関数のドキュメントで、再開されるまで実行を一時停止します。
- [リファレンス: Workflow.then() | ワークフローの構築 | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/then): ワークフロー内の `.then()` メソッドに関するドキュメントで、ステップ間の順次依存関係を作成します。
- [リファレンス: Workflow.until() | ワークフロー内のループ | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/until): Mastra ワークフローにおける `.until()` メソッドのドキュメントで、指定された条件が真になるまでステップを繰り返します。
- [リファレンス: run.watch() | ワークフロー | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/watch): ワークフロー内の `.watch()` メソッドに関するドキュメントで、ワークフローの実行状況を監視します。
- [リファレンス: Workflow.while() | ワークフロー内のループ | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/while): Mastra ワークフローにおける `.while()` メソッドのドキュメントで、指定された条件が真である限りステップを繰り返します。
- [リファレンス: Workflow クラス | ワークフローの構築 | Mastra ドキュメント](https://mastra.ai/ja/reference/workflows/workflow): Mastra の Workflow クラスに関するドキュメントで、条件分岐とデータ検証を伴う複雑な操作のシーケンスのための状態マシンを作成することができます。
- [ショーケース](https://mastra.ai/ja/showcase): Mastraで構築されたこれらのアプリケーションをご覧ください