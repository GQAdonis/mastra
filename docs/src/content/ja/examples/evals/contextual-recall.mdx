---
title: "例: 文脈的リコール | Evals | Mastra Docs"
description: 文脈的リコール指標を使用して、応答がどの程度文脈情報を取り入れているかを評価する例。
---

import { GithubLink } from "../../../../components/github-link";

# コンテクストリコール

この例では、Mastraのコンテクストリコールメトリックを使用して、提供されたコンテクストからの情報をどれだけ効果的に応答に組み込んでいるかを評価する方法を示します。

## 概要

この例では、次の方法を示します：

1. Contextual Recall メトリックを設定する
2. コンテキストの組み込みを評価する
3. リコールスコアを分析する
4. 異なるリコールレベルを処理する

## セットアップ

### 環境セットアップ

環境変数を設定してください：

```bash filename=".env"
OPENAI_API_KEY=your_api_key_here
```

### 依存関係

必要な依存関係をインポートします：

```typescript copy showLineNumbers filename="src/index.ts"
import { openai } from '@ai-sdk/openai';
import { ContextualRecallMetric } from '@mastra/evals/llm';
```

## 使用例

### 高リコール例

すべてのコンテキスト情報を含む応答を評価します：

```typescript copy showLineNumbers{5} filename="src/index.ts"
const context1 = [
  '製品の特徴にはクラウド同期が含まれます。',
  'オフラインモードが利用可能です。',
  '複数のデバイスをサポートします。',
];

const metric1 = new ContextualRecallMetric(openai('gpt-4o-mini'), {
  context: context1,
});

const query1 = '製品の主な特徴は何ですか？';
const response1 = '製品の特徴にはクラウド同期、オフラインモードのサポート、複数のデバイスでの作業が含まれます。';

console.log('例1 - 高リコール:');
console.log('コンテキスト:', context1);
console.log('クエリ:', query1);
console.log('応答:', response1);

const result1 = await metric1.measure(query1, response1);
console.log('メトリック結果:', {
  score: result1.score,
  reason: result1.info.reason,
});
// 出力例:
// メトリック結果: { score: 1, reason: '出力のすべての要素がコンテキストによってサポートされています。' }
```

### 混合リコール例

一部のコンテキスト情報を含む応答を評価します：

```typescript copy showLineNumbers{27} filename="src/index.ts"
const context2 = [
  'Pythonは高水準プログラミング言語です。',
  'Pythonはコードの可読性を重視しています。',
  'Pythonは複数のプログラミングパラダイムをサポートします。',
  'Pythonはデータサイエンスで広く使用されています。',
];

const metric2 = new ContextualRecallMetric(openai('gpt-4o-mini'), {
  context: context2,
});

const query2 = 'Pythonの主な特徴は何ですか？';
const response2 = 'Pythonは高水準プログラミング言語です。また、Pythonは蛇の一種でもあります。';

console.log('例2 - 混合リコール:');
console.log('コンテキスト:', context2);
console.log('クエリ:', query2);
console.log('応答:', response2);

const result2 = await metric2.measure(query2, response2);
console.log('メトリック結果:', {
  score: result2.score,
  reason: result2.info.reason,
});
// 出力例:
// メトリック結果: { score: 0.5, reason: '出力の半分のみがコンテキストによってサポートされています。' }
```

### 低リコール例

ほとんどのコンテキスト情報を欠いている応答を評価します：

```typescript copy showLineNumbers{53} filename="src/index.ts"
const context3 = [
  '太陽系には8つの惑星があります。',
  '水星は太陽に最も近いです。',
  '金星は最も暑い惑星です。',
  '火星は赤い惑星と呼ばれています。',
];

const metric3 = new ContextualRecallMetric(openai('gpt-4o-mini'), {
  context: context3,
});

const query3 = '太陽系について教えてください。';
const response3 = '木星は太陽系で最大の惑星です。';

console.log('例3 - 低リコール:');
console.log('コンテキスト:', context3);
console.log('クエリ:', query3);
console.log('応答:', response3);

const result3 = await metric3.measure(query3, response3);
console.log('メトリック結果:', {
  score: result3.score,
  reason: result3.info.reason,
});
// 出力例:
// メトリック結果: { score: 0, reason: '出力のいずれもコンテキストによってサポートされていません。' }
```

## 結果の理解

このメトリックは以下を提供します：

1. 0から1の間のリコールスコア：
   - 1.0: 完全なリコール - すべてのコンテキスト情報が使用された
   - 0.7-0.9: 高いリコール - ほとんどのコンテキスト情報が使用された
   - 0.4-0.6: 混合リコール - 一部のコンテキスト情報が使用された
   - 0.1-0.3: 低いリコール - わずかなコンテキスト情報が使用された
   - 0.0: リコールなし - コンテキスト情報が使用されなかった

2. スコアの詳細な理由、以下を含む分析：
   - 情報の取り込み
   - コンテキストの欠如
   - 応答の完全性
   - 全体的なリコールの質

<br />
<br />
<hr className="dark:border-[#404040] border-gray-300" />
<br />
<br />
<GithubLink
  link={
    "https://github.com/mastra-ai/mastra/blob/main/examples/basics/evals/contextual-recall"
  }
/>
